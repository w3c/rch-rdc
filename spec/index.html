<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type" />
<title>RDF Dataset Canonicalization</title>
<script class="remove" src="https://www.w3.org/Tools/respec/respec-w3c"></script>
<script src="common/common.js" class="remove" defer></script>
<script class="remove" src="common/biblio.js"></script>
<script class="remove">
//<![CDATA[
  var respecConfig = {
    localBiblio:          rch.localBiblio,
    specStatus:           "ED",
    copyrightStart:       "2010",

    // the specification's short name, as in http://www.w3.org/TR/short-name/
    shortName:            "rdf-canon",
    subtitle:             "A Standard RDF Dataset Canonicalization Algorithm",
    // if you wish the publication date to be other than today, set this
    // publishDate:  "2009-08-06",

    github: "https://github.com/w3c/rdf-canon/",

    // editors, add as many as you like
    // only "name" is required
    editors:  [
      { name:       "Dave Longley",
        url:        "https://digitalbazaar.com/author/dlongley/",
        w3cid:      "48025",
        company:    "Digital Bazaar",
        companyURL: "https://digitalbazaar.com/" },
      { name:       "Gregg Kellogg",
        url:        "https://greggkellogg.net/",
        w3cid:      "44770" },
      { name:       "Dan Yamamoto",
        url:        "https://github.com/yamdan",
        w3cid:      "139477" }
    ],

    // formerEditors, add as many as you like
    // only "name" is required
    formerEditors:  [
      { name:       "Manu Sporny",
        url:        "http://manu.sporny.org/",
        w3cid:      "41758",
        company:    "Digital Bazaar",
        companyURL: "https://digitalbazaar.com/",
        note:       "CG Report" }
      ],

    // authors, add as many as you like.
    // This is optional, uncomment if you have authors as well as editors.
    // only "name" is required. Same format as editors.
    authors:  [
      { name:       "Dave Longley",
        url:        "https://digitalbazaar.com/author/dlongley/",
        w3cid:      "48025",
        company:    "Digital Bazaar",
        companyURL: "https://digitalbazaar.com/" }
    ],

    // name of the 
    group: "rch",
    testSuiteURI: "https://w3c.github.io/rdf-canon/tests/",
    xref: ["rdf11-concepts", "rdf11-mt"],
    doJsonLd:     true,
    wgPublicList: "public-rch-wg"
  };
//]]>
</script>
<style>
  .hl-bold { font-weight: bold; color: #0a3; }
  .comment { color: #999; }
  table, thead, tr, td { padding: 5px; border-width: 1px; border-spacing: 0px; border-style: solid; border-collapse: collapse; }
  .algorithm ol {
    counter-reset: numsection;
    list-style-type: none;
  }
  .algorithm ol>li {
    margin: 0.5em 0;
  }
  .algorithm ol>li:before {
    font-weight: bold;
    counter-increment: numsection;
    content: counters(numsection, ".") ") ";
  }
  a.externalDFN {border-bottom:  1px solid #99c; font-style: italic;}

  code { color: #c63501; }

  details {
    background-color: rgb(245,245,245);
    border-left: 0.3em solid rgb(200,200,200);
    padding: 0.3em;
  }
  summary {font-size: small; }
</style>
</head>

<body>
<section id="abstract">
  <p>RDF [[RDF11-CONCEPTS]] describes a graph-based data model for making claims
    about the world and provides the foundation for reasoning upon that graph
    of information. At times, it becomes necessary to compare the differences
    between sets of graphs, digitally sign them, or generate short identifiers
    for graphs via hashing algorithms. This document outlines an algorithm for
    normalizing <a>RDF datasets</a> such that these operations can be
    performed.</p>
</section>

<section id="sotd">
  <p>This document describes the <a>URDNA2015</a> algorithm for canonicalizing
    RDF datasets, which was the input from the
    <a href="https://www.w3.org/community/credentials/">W3C Credentials Community Group</a>
    published as [[CCG-RDC-FINAL]].
    There are other canonicalization algorithms actively being considered
    by the Working Group â€“ notably [[Hogan-Canonical-RDF]];
    future versions of this document may change accordingly.
    See <span class="issue" data-number="6">Issue 6: Compare the two algorithms, and decide on basis for our work</span>
    and <span class="issue" data-number="10">Issue 10: C14N choice criteria</span>
    for further discussion.</p>
</section>

<section id="introduction">
  <h2>Introduction</h2>

  <p>When data scientists discuss canonicalization,
    they do so in the context of achieving a particular set of goals.
    Since the same information may sometimes be expressed in a variety of different ways,
    it often becomes necessary to transform each of these
    different ways into a single, standard representation.
    With a standard representation, the differences between
    two different sets of data can be easily determined,
    a cryptographically-strong hash identifier can be generated for a particular
    set of data,
    and a particular set of data may be digitally-signed for later
    verification.</p>

  <p>In particular, this specification is about normalizing
    <a>RDF datasets</a>, which are collections of graphs. Since
    a directed graph can express the same information in more than one
    way, it requires canonicalization to achieve the aforementioned goals
    and any others that may arise via serendipity.</p>

  <p>Most <a>RDF datasets</a> can be normalized fairly quickly, in terms
    of algorithmic time complexity. However, those that contain nodes that do
    not have globally unique identifiers pose a greater challenge. Normalizing
    these datasets presents the <dfn>graph isomorphism</dfn> problem, a
    problem that is believed to be difficult to solve quickly. More formally,
    it is believed to be an NP-Intermediate problem, that is, neither known to
    be solvable in polynomial time nor NP-complete. Fortunately, existing real
    world data is rarely modeled in a way that manifests this problem and new
    data can be modeled to avoid it. In fact, software systems can detect a
    problematic dataset and may choose to assume it's an attempted denial of
    service attack, rather than a real input, and abort.</p>

  <p>This document outlines an algorithm for generating a canonical
    serialization of an <a>RDF dataset</a> given an <a>RDF dataset</a> as input.
    The algorithm is called the
    <strong>Universal RDF Dataset Canonicalization Algorithm 2015</strong> or
    <a>URDNA2015</a>.</p>

  <section id="intro-uses">
    <h2>Uses of Dataset Canonicalization</h2>
    <p>There are different use cases where graph or dataset canonicalization are important:</p>
    <ul>
      <li>Determining if one serialization is isomorphic to another.</li>
      <li>Digital signing of graphs (datasets) independent of serialization or format.</li>
      <li>Comparing two graphs (datasets) to find differences.</li>
      <li>Communicating change sets when remotely updating an <a data-cite="RDF11-CONCEPTS#dfn-rdf-source">RDF source</a>.</li>
    </ul>
    <p>A canonicalization algorithm is necessary, but not necessarily sufficient, to handle many of these use cases. The use of <a>blank nodes</a> in RDF graphs and datasets has a long history and creates inevitable complexities. Blank nodes are used for different purposes:</p>
    <ul>
      <li>when a well known identifier for a node is not known, or the author of a document chooses not to unambiguously name that node,</li>
      <li>when a node is used to stitch together parts of a graph and the nodes themselves are not interesting (e.g., <a data-cite="RDF11-MT#rdf-collections">RDF Collections</a> in [[RDF11-MT]]),</li>
      <li>when someone is trying to create an intentionally difficult graph topology.</li>
    </ul>
    <p>Furthermore,
      RDF semantics dictate that deserializing an RDF document
      results in the creation of unique <a>blank nodes</a>,
      unless it can be determined that on each occasion,
      the <a>blank node</a> identifies the same resource.
      This is due to the fact that <a>blank node identifiers</a>
      are an aspect of a concrete RDF syntax
      and are not intended to be persistent or portable.
      Within the abstract RDF model,
      blank nodes do not have identifiers
      (although some
      RDF store
      implementations may use stable identifiers and may choose to make them portable).
      See <a data-cite="RDF11-CONCEPTS#section-blank-nodes">Blank Nodes</a>
      in [[!RDF11-CONCEPTS]] for more information.</p>

    <p>RDF does have a provision for allowing blank nodes
      to be published in an externally identifiable way through the use of
      <a data-cite="RDF11-CONCEPTS#dfn-skolem-iri">Skolem IRIs</a>,
      which allow a given RDF store to replace the use of blank nodes
      in a concrete syntax with <a>IRIs</a>,
      which then serve to repeatably identify that blank node within that particular RDF store;
      however, this is not generally useful for talking about the
      same graph in different RDF stores,
      or other concrete representations.
      In any case, a stable <a>blank node identifier</a> defined for one
      RDF store or serialization is arbitrary,
      and typically not relatable to the context within which it is used.</p>

    <p>This specification defines an algorithm for creating stable <a>blank node identifiers</a> repeatably for different serializations possibly using individualized <a>blank node identifiers</a> of the same RDF graph (dataset) by grounding each <a>blank node</a> through the nodes to which it is connected, essentially creating <em>Skolem <a>blank node identifiers</a></em>. As a result, a graph signature can be obtained by hashing a canonical serialization of the resulting <a>normalized dataset</a>, allowing for the isomorphism and digital signing use cases. As blank node identifiers can be stable even with other changes to a graph (dataset), in some cases it is possible to compute the difference between two graphs (datasets), for example if changes are made only to ground triples, or if new blank nodes are introduced which do not create an automorphic confusion with other existing blank nodes. If any information which would change the generated blank node identifier, a resulting diff might indicate a greater set of changes than actually exists.</p>

    <div class="ednote">
      <p>Add descriptions for relevant historical discussions and prior art:</p>
      <dl>
        <dt>[[DesignIssues-Diff]]</dt>
        <dd>TimBL's design note on problems with Diff.</dd>
        <dt>[[eswc2014Kasten]]</dt>
        <dd>A Framework for Iterative Signing of Graph Data on the Web.</dd>
        <dt>[[Hogan-Canonical-RDF]]</dt>
        <dd>Aiden Hogan's paper on canonicalizing RDF</dd>
        <dt>[[HPL-2003-142]]</dt>
        <dd>Jeremy J. Carroll's paper on signing RDF graphs.</dd>
      </dl>
    </div>
  </section>

  <section id="how-to-read">
    <h2>How to Read this Document</h2>

    <p>This document is a detailed specification for an <a>RDF dataset</a>
      canonicalization algorithm. The document is primarily intended for the
      following audiences:</p>

    <ul>
      <li>Software developers that want to implement an <a>RDF dataset</a>
        canonicalization algorithm.</li>
      <li>Masochists.</li>
    </ul>

    <p>To understand the basics in this specification you must be familiar with
      basic RDF concepts [[!RDF11-CONCEPTS]]. A working knowledge of
      <a href="https://en.wikipedia.org/wiki/Graph_theory">graph theory</a> and
      <a href="https://en.wikipedia.org/wiki/Graph_isomorphism">graph isomorphism</a>
      is also recommended.</p>
  </section>

  <section id="typo-conventions" class="informative">
    <h2>Typographical conventions</h2>
    <div data-include="common/typographical-conventions.html"></div>
  </section>
</section>

<section id="conformance"></section>

<section id="terminology" class="normative">
  <h2>Terminology</h2>

  <dl>
    <dt><dfn>string</dfn></dt><dd>
      A string is a sequence of zero or more Unicode characters.</dd>
    <dt><code>true</code> and <code>false</code></dt><dd>
      Values that are used to express one of two possible boolean states.</dd>
    <dt><dfn data-lt="internationalized resource identifier|iri|iris"><abbr title="Internationalized Resource Identifier">IRI</abbr></dfn></dt>
    <dd>An <a>IRI</a> (Internationalized Resource Identifier) is a string that conforms to the syntax
      defined in [[RFC3987]].</dd>
    <dt><dfn data-lt="subject|subjects">subject</dfn></dt>
    <dd>A <a data-cite="RDF11-CONCEPTS#dfn-subject">subject</a>
      as specified by [[!RDF11-CONCEPTS]].</dd>
    <dt><dfn data-lt="predicate|predicates">predicate</dfn></dt>
    <dd>A <a data-cite="RDF11-CONCEPTS#dfn-predicate">predicate</a>
      as specified by [[!RDF11-CONCEPTS]].</dd>
    <dt><dfn data-lt="object|objects">object</dfn></dt>
    <dd>An <a data-cite="RDF11-CONCEPTS#dfn-object">object</a>
      as specified by [[!RDF11-CONCEPTS]].</dd>
    <dt><dfn data-lt="rdf triple|rdf triples|triple|triples">RDF triple</dfn></dt>
    <dd>A <a data-cite="RDF11-CONCEPTS#dfn-rdf-triple">triple</a>
      as specified by [[!RDF11-CONCEPTS]].</dd>
    <dt><dfn data-lt="rdf graph|rdf graphs|graph|graphs">RDF graph</dfn></dt>
    <dd>An <a data-cite="RDF11-CONCEPTS#dfn-rdf-graph">RDF graph</a>
      as specified by [[!RDF11-CONCEPTS]].</dd>
    <dt><dfn data-lt="graph name|graph names">graph name</dfn></dt>
    <dd>A <a data-cite="RDF11-CONCEPTS#dfn-graph-name">graph name</a>
      as specified by [[!RDF11-CONCEPTS]].</dd>
    <dt><dfn>default graph</dfn></dt>
    <dd>The <a data-cite="RDF11-CONCEPTS#dfn-default-graph">default graph</a>
      as specified by [[!RDF11-CONCEPTS]].</dd>
    <dt><dfn data-lt="quad|quads">quad</dfn></dt>
    <dd>A tuple composed of <a>subject</a>, <a>predicate</a>, <a>object</a>, and <a>graph name</a>.
      This is a generalization of an <a>RDF triple</a> along with a <a>graph name</a>.</dd>
    <dt><dfn data-lt="rdf dataset|rdf datasets|dataset|datasets">RDF dataset</dfn></dt>
    <dd>A <a data-cite="RDF11-CONCEPTS#dfn-rdf-dataset">dataset</a>
      as specified by [[!RDF11-CONCEPTS]].
      For the purposes of this specification, an <a>RDF dataset</a>
      is considered to be a set of <a>quads</a></dd>
    <dt><dfn data-lt="blank node|blank nodes">blank node</dfn></dt>
    <dd>A <a data-cite="RDF11-CONCEPTS#dfn-blank-node">blank node</a>
      as specified by [[!RDF11-CONCEPTS]]. In short, it is a node in a graph that is
      neither an <a>IRI</a>, nor a
      <a data-cite="RDF11-CONCEPTS#dfn-literal">literal</a>.</dd>
    <dt><dfn data-lt="blank node identifier|blank node identifiers">blank node identifier</dfn></dt>
    <dd>A <a data-cite="RDF11-CONCEPTS#dfn-blank-node-identifier">blank node identifier</a>
      as specified by [[!RDF11-CONCEPTS]]. In short, it is a <a>string</a> that begins
      with <code>_:</code> that is used as an identifier for an
      <a>blank node</a>. <a>Blank node identifiers</a>
      are typically implementation-specific local identifiers; this document
      specifies an algorithm for deterministically specifying them.</dd>
  </dl>
</section>

<section id="canonicalization">
  <h2>Canonicalization</h2>

  <p>Canonicalization is the process of transforming an
    <a>input dataset</a> to a <a>normalized dataset</a>. That
    is, any two <a>input datasets</a> that contain the same
    information, regardless of their arrangement, will be transformed into
    identical <a>normalized dataset</a>. The problem requires directed
    graphs to be deterministically ordered into sets of nodes and edges. This
    is easy to do when all of the nodes have globally-unique identifiers, but
    can be difficult to do when some of the nodes do not. Any nodes without
    globally-unique identifiers must be issued deterministic identifiers.</p>

  <p class="ednote">Strictly speaking, the normalized dataset must be serialized to be stable, as within a dataset, blank node identifiers have no meaning. This specification defines a <a>normalized dataset</a> to include stable identifiers for blank nodes, but practical uses of this will always generate a canonical serialization of such a dataset.</p>

  <p>In time, there may be more than one canonicalization algorithm and,
    therefore, for identification purposes, this algorithm is named the
    "Universal RDF Dataset Canonicalization Algorithm 2015"
    (<abbr title="Universal RDF Dataset Canonicalization Algorithm 2015"><dfn class="export">URDNA2015</dfn></abbr>).</p>

  <p class="ednote">This statement is overly prescriptive and does not include normative language.
    This spec should describe the theoretical basis for graph canonicalization and describe
    behavior using normative statements. The explicit algorithms should follow as an informative appendix.</p>

  <section id="canon-overview" class="informative">
    <h3>Overview</h3>

    <p>To determine a canonical labeling, <a>URDNA2015</a> considers the
      information connected to each blank node.
      Nodes with unique first degree information can immediately be issued a canonical identifier
      via the <a href="#issue-identifier">Issue Identifier algorithm</a>.
      When a node has non-unique first degree information,
      it is necessary to determine all information that is transitively connected
      to it throughout the entire dataset.
      <a href="#hash-1d-quads" class="sectionRef"></a> defines a
      nodeâ€™s first degree information via its first degree hash. </p>

    <p>Hashes are computed from the information of each blank node.
      These hashes encode the mentions incident to each blank node.
      The <a>hash</a> of a string <var>s</var>, is the lower-case,
      hexidecimal representation of the result of passing <var>s</var>
      through a cryptographic hash function.
      URDNA2015 uses the SHA-256 hash algorithm.</p>
  </section>

  <section id="canon-terms">
    <h2>Canonicalization Algorithm Terms</h2>
    <dl>
      <dt><dfn data-lt="input dataset|input datasets">input dataset</dfn></dt>
      <dd>The abstract <a>RDF dataset</a> that is provided as input to
        the algorithm.</dd>
      <dt><dfn>normalized dataset</dfn></dt>
      <dd>The immutable, abstract <a>RDF dataset</a> and set of normalized
        <a>blank node identifiers</a> that are produced as output by the algorithm. A <a>normalized dataset</a> is a restriction on an <a>RDF dataset</a> where all nodes are labeled, and <a>blank nodes</a> are labeled with <a>blank node identifiers</a> consistent with running this algorithm on a base <a>RDF dataset</a>. A concrete serialization of an <a>normalized dataset</a> MUST label all <a>blank nodes</a> using these stable <a>blank node identifiers</a>.</dd>
      <dt><dfn>identifier issuer</dfn></dt>
      <dd>An identifier issuer is used to issue new <a>blank node identifier</a>. It
        maintains a
        <a href="#bn-issuer-state">blank node identifier issuer state</a>.</dd>
      <dt><dfn>hash</dfn></dt>
      <dd>The lowercase, hexadecimal representation of a message digest.</dd>
      <dt><dfn>hash algorithm</dfn></dt>
      <dd>The hash algorithm used by <a>URDNA2015</a>, namely, SHA-256.</dd>
      <dt><dfn data-lt="code point order|code point ordered">Unicode code point order</dfn></dt>
      <dd>This refers to determining the order of two Unicode strings (`A` and `B`),
        using <a data-cite="XPATH-FUNCTIONS#codepoint-collation">Unicode Codepoint Collation</a>,
        as defined in [[XPATH-FUNCTIONS]],
        which defines a
        <a href="https://en.wikipedia.org/wiki/Total_order">total ordering</a>
        of <a>strings</a> comparing code points.
      </dd>
      <dt><dfn data-lt="mention">mention set</dfn></dt>
      <dd>The set of all <a>quads</a> in a <a>dataset</a>
        that mention a node <var>n</var> is called its <a>mention set</a> of <var>n</var>,
        denoted <var>Q<sub>n</sub></var>.</dd>
      <dt><dfn>gossip path</dfn></dt>
      <dd>The gossip path between two <a>blank nodes</a> contained within
        <a>quads</a> in a <a>dataset</a>, where the path is a sequence
        of nodes and quads such that the first quad includes
        the starting node as an component, and the last quad includes
        the ending node as an component with each quad in the path
        containing both the preceding and following nodes.</dd>
    </dl>
  </section>

  <section id="canon-state">
    <h2>Canonicalization State</h2>

    <p>When performing the steps required by the canonicalization algorithm,
      it is helpful to track state in a data structure called the
      <dfn>canonicalization state</dfn>. The information contained in the
      <a>canonicalization state</a> is described below.</p>

    <dl>
      <dt><dfn>blank node to quads map</dfn></dt>
      <dd>A <a data-cite="INFRA#ordered-map">map</a> that relates a <a>blank node identifier</a> to
        the <a>quads</a> in which they appear in the
        <a>input dataset</a>.</dd>
      <dt><dfn>hash to blank nodes map</dfn></dt>
      <dd>A <a data-cite="INFRA#ordered-map">map</a> that relates a <a>hash</a> to a list of
        <a>blank node identifiers</a>.</dd>
      <dt><dfn>canonical issuer</dfn></dt>
      <dd>An <a>identifier issuer</a>, initialized with the
        prefix <code>_:c14n</code>, for issuing canonical
        <a>blank node identifiers</a>.
        <div class="ednote">
          Mapping all <a>blank nodes</a> to use this
          identifier spec means that an <a>RDF dataset</a> composed of two
          different <a>RDF graphs</a> will use different
          identifiers then that for the graphs taken independently. This may
          happen anyway, due to <a
          href="https://en.wikipedia.org/wiki/Automorphism">automorphisms</a>,
          or overlapping statements, but an identifier based on the resulting
          <a>hash</a> along with an issue sequence number specific to that <a>hash</a> would
          stand a better chance of surviving such minor changes, and allow the
          resulting information to be useful for <a href="https://www.w3.org/2001/sw/wiki/How_to_diff_RDF">RDF Diff</a>.
        </div>
      </dd>
    </dl>
  </section>

  <section id="bn-issuer-state">
    <h2>Blank Node Identifier Issuer State</h2>

    <p>During the canonicalization algorithm, it is sometimes necessary to
      issue new identifiers to <a>blank nodes</a>. The
      <a href="#issue-identifier">Issue Identifier algorithm</a> uses an
      <a>identifier issuer</a> to accomplish this task. The information
      an <a>identifier issuer</a> needs to keep track of is described
      below.</p>

    <dl>
      <dt><dfn>identifier prefix</dfn></dt>
      <dd>The identifier prefix is a string that is used at the beginning of an
        <a>blank node identifier</a>. It should be initialized to a
        string that is specified by the canonicalization algorithm. When
        generating a new <a>blank node identifier</a>, the prefix
        is concatenated with a <a>identifier counter</a>. For example,
        <code>_:c14n</code> is a proper initial value for the
        <a>identifier prefix</a> that would produce
        <a>blank node identifiers</a> like <code>_:c14n1</code>.</dd>
      <dt><dfn>identifier counter</dfn></dt>
      <dd>A counter that is appended to the <a>identifier prefix</a> to
        create an <a>blank node identifier</a>. It is initialized to
        <code>0</code>.</dd>
      <dt><dfn>issued identifiers map</dfn></dt>
      <dd>An <a data-cite="INFRA#ordered-map">ordered map</a> that relates existing identifiers to issued identifiers,
        to prevent issuance of more than one new identifier per existing identifier,
        and to allow <a>blank nodes</a> to
        be reassigned identifiers some time after issuance.</dd>
    </dl>
  </section>

  <section id="canon-algorithm" class="algorithm">
    <h2>Canonicalization Algorithm</h2>
  <p class="ednote">At the time of writing, there are several open issues that will determine important details of the canonicalization algorithm.</p>
        <div class="issue" data-number="4"></div>
        <div class="issue" data-number="6"></div>
        <div class="issue" data-number="7"></div>
        <div class="issue" data-number="8"></div>
        <div class="issue" data-number="10"></div>
        <div class="issue" data-number="11"></div>


    <p>The canonicalization algorithm converts an <a>input dataset</a>
      into a <a>normalized dataset</a>. This algorithm will assign
      deterministic identifiers to any <a>blank nodes</a> in the
      <a>input dataset</a>.</p>

    <p class="ednote">Documenting the algorithm is a WIP, various steps will
      become more detailed in time.</p>

    <section id="canon-algo-overview" class="informative">
      <h3>Overview</h3>

      <p><a>URDNA2015</a> canonically labels an <a>RDF dataset</a>.
        In URDNA2015, an RDF dataset <var>D</var>
        is represented as a set of <a>quads</a> of the form `&lt; s, p, o, g >`
        where the graph component `g` is empty if and only if the
        <a>triple</a> `&lt; s, p, o >` is in the <a>default graph</a>.
        This algorithm considers an RDF dataset to be a set of quads.
        Two RDF datasets are considered to be isomorphic (i.e., the same modulo blank nodes),
        if and only if they return the same canonically labeled list of quads
        via <a>URDNA2015</a>.</p>

      <p><a>URDNA2015</a> consists of several sub-algorithms.
        These sub-algorithms are introduced in the following sub-sections.
        First, we give a high level summary of URDNA2015.</p>

      <ol>
        <li id="ca-hl-1"><strong>Initialization</strong>.
          Initialize the state needed for the rest of the algorithm
          using <a href="#canon-state" class="sectionRef"></a>.</li>
        <li id="ca-hl-2"><strong>Compute first degree hashes</strong>.
          Compute the first degree hash for each blank node in the dataset using <a href="#hash-1d-quads" class="sectionRef"></a>.</li>
        <li id="ca-hl-3"><strong>Canonically label unique nodes</strong>.
          Assign canonical identifiers via <a href="#issue-identifier" class="sectionRef"></a>,
          in <a>Unicode code point order</a>, to each blank node whose first degree hash is unique.</li>
        <li id="ca-hl-4"><strong>Compute N-degree hashes for non-unique nodes</strong>.
          For each repeated first degree hash (proceeding in <a>Unicode code point order</a>),
          compute the N-degree hash via <a href="#hash-nd-quads" class="sectionRef"></a>
          of every unlabeled blank node that corresponds to the given repeated hash.</li>
        <li id="ca-hl-5"><strong>Canonically label remaining nodes</strong>.
          In <a>Unicode code point order</a> of the N-degree hashes,
          issue canonical identifiers to each corresponding blank node using
          <a href="#issue-identifier" class="sectionRef"></a>.
          If more than one node produces the same N-degree hash,
          the order in which these nodes receive a canonical identifier does not matter.</li>
        <li id="ca-hl-6"><strong>Finish</strong>. Return the normalized dataset.</li>
      </ol>
    </section>

    <section id="canon-algo-algo">
      <h3>Algorithm</h3>

      <ol>
        <li id="ca-1">Create the <a>canonicalization state</a>.
          <details>
            <summary>Explaination</summary>
            <p>This has the effect of initializing the
              <a>blank node to quads map</a>,
              and the <a>hash to blank nodes map</a>,
              as well as instantiating a new <a>canonical issuer</a>.</p>
          </details>
        </li>
        <li id="ca-2">For every <a>quad</a> <var>Q</var> in <a>input dataset</a>:
          <ol>
            <li id="ca-2-1">For each <a>blank node</a> that is a component of <var>Q</var>,
              add a reference to the <var>Q</var> from the
              <a data-cite="INFRA#map-entry">map entry</a> for the
              <a>blank node identifier</a> <var>identifier</var>
              in the <a>blank node to quads map</a>,
              creating a new entry if necessary.
              <div class="issue" data-number="15">
                It seems that <var>Q</var> must be normalized,
                so that literals with different syntactic representations
                but the same semantic representations are merged,
                and that two graphs differing in the syntactic representation
                of a literal will produce the same set of blank node identifiers.</div>
            </li>
          </ol>
        </li>
        <li id="ca-3">Create a list of non-normalized <a>blank node identifiers</a>
          <var>non-normalized identifiers</var> and populate it using the <a data-cite="INFRA#map-key">keys</a>
          from the <a>blank node to quads map</a>.</li>
        <li id="ca-4">For each <a>blank node identifier</a> <var>n</var> in <var>non-normalized identifiers</var>:
          <ol>
            <li id="ca-4-1">Create a <a>hash</a>, <var>h<sub>f</sub>(n)</var>,
              for <var>n</var> according to the
              <a href="#hash-1d-quads">Hash First Degree Quads algorithm</a>.</li>
            <li id="ca-4-2">Add <var>h<sub>f</sub>(n)</var> and <var>n</var> to
              <a>hash to blank nodes map</a>, including repetitions,
              creating a new entry if necessary.</li>
          </ol>
        </li>
        <li id="ca-5">For each <var>hash</var> to <var>identifier list</var>
          <a data-cite="INFRA#map-entry">map entry</a> in
          <a>hash to blank nodes map</a>, <a>code point ordered</a> by <var>hash</var>:
          <ol>
            <li id="ca-5-1">If <var>identifier list</var> has more than one entry,
              continue to the next mapping.</li>
            <li id="ca-5-2">Use the
              <a href="#issue-identifier">Issue Identifier algorithm</a>,
              passing <a>canonical issuer</a> and the
              single <a>blank node identifier</a>, <var>identifier</var> in
              <var>identifier list</var> to issue a
              canonical replacement identifier for <var>identifier</var>.</li>
            <li id="ca-5-3">Remove <var>identifier</var> from
              <var>non-normalized identifiers</var>.</li>
            <li id="ca-5-4">Remove the <a data-cite="INFRA#map-entry">map entry</a> for <var>hash</var> from the
              <a>hash to blank nodes map</a>.</li>
          </ol>
        </li>
        </li>
        <li id="ca-6">For each <var>hash</var> to <var>identifier list</var>
          <a data-cite="INFRA#map-entry">map entry</a> in
          <a>hash to blank nodes map</a>, <a>code point ordered</a> by
          <var>hash</var>:
          <ol>
            <li id="ca-6-1">Create <var>hash path list</var> where each item will be a result
              of running the
              <a href="#hash-nd-quads">Hash N-Degree Quads algorithm</a>.</li>
            <li id="ca-6-2">For each <a>blank node identifier</a>
              <var>n</var> in <var>identifier list</var>:
              <ol>
                <li id="ca-6-2-1">If a canonical identifier has already been issued for
                  <var>n</var>, continue to the next
                  <a>blank node identifier</a>.</li>
                <li id="ca-6-2-2">Create <var>temporary issuer</var>, an
                  <a>identifier issuer</a> initialized with the prefix
                  <code>_:b</code>.</li>
                <li id="ca-6-2-3">Use the
                  <a href="#issue-identifier">Issue Identifier algorithm</a>,
                  passing <var>temporary issuer</var> and <var>n</var>, to
                  issue a new temporary <a>blank node identifier</a> <var>b<sub>n</sub></var>
                  to <var>n</var>.</li>
                <li id="ca-6-2-4">Run the
                  <a href="#hash-nd-quads">Hash N-Degree Quads algorithm</a>,
                  passing <var>temporary issuer</var>, and append the
                  result to the <var>hash path list</var>.</li>
              </ol>
            </li>
            <li id="ca-6-3">For each <var>result</var> in the <var>hash path list</var>,
              <a>code point ordered</a> by the <var>hash</var> in <var>result</var>:
              <ol>
                <li id="ca-6-3-1">For each <a>blank node identifier</a>,
                  <var>existing identifier</var>, that was issued a temporary
                  identifier by <var>identifier issuer</var> in <var>result</var>, issue
                  a canonical identifier, in the same order, using the
                  <a href="#issue-identifier">Issue Identifier algorithm</a>,
                  passing <a>canonical issuer</a> and
                  <var>existing identifier</var>.
              </ol>
            </li>
          </ol>
        </li>
        <li id="ca-7">For each <a>quad</a>, <var>q</var>, in <a>input dataset</a>:
          <ol>
            <li id="ca-7-1">Create a copy, <var>quad copy</var>, of <var>q</var> and replace any
              existing <a>blank node identifier</a> <var>n</var> using the
              canonical identifiers previously issued
              by <a>canonical issuer</a>.</li>
            <li id="ca-7-2">Add <var>quad copy</var> to the
              <a>normalized dataset</a>.</li>
          </ol>
        </li>
        <li id="ca-8">Return the <a>normalized dataset</a>.</li>
      </ol>
    </section>
  </section>

  <section id="issue-identifier" class="algorithm">
    <h2>Issue Identifier Algorithm</h2>
    <!--section id="issue-identifier-overview" class="informative">
      <h3>Overview</h3>
    </section-->

    <section id="issue-identifier-algorithm">
      <h3>Algorithm</h3>

      <p>This algorithm issues a new <a>blank node identifier</a> for
        a given existing <a>blank node identifier</a>. It also updates
        state information that tracks the order in which new
        <a>blank node identifiers</a> were issued.</p>

      <p>This algorithm takes an <a>identifier issuer</a> <var>I</var> and an
        <var>existing identifier</var> as inputs. The output is a new
        <var>issued identifier</var>. The steps of the algorithm are:</p>

      <ol>
        <li id="iia-1">If there is a
          <a data-cite="INFRA#map-entry">map entry</a> for <var>existing identifier</var> in
          <a>issued identifiers map</a> of <var>I</var>,
          return it.</li>
        <li id="iia-2">Generate <var>issued identifier</var> by concatenating
          <a>identifier prefix</a> with the string value of
          <a>identifier counter</a>.</li>
        <li id="iia-3">Add an <a data-cite="INFRA#map-entry">entry</a>
          mapping <var>existing identifier</var> to <var>issued identifier</var>
          to the <a>issued identifiers map</a> of <var>I</var>.</li>
        <li id="iia-4">Increment <a>identifier counter</a>.</li>
        <li id="iia-5">Return <var>issued identifier</var>.</li>
      </ol>
    </section>
  </section>

  <section id="hash-1d-quads" class="algorithm">
    <h2>Hash First Degree Quads</h2>

    <p>This algorithm calculates a <a>hash</a> for a given <a>blank node</a>
      across the <a>quads</a> in a <a>dataset</a> in which that blank node
      is a component.
      If the hash uniquely identifies that blank node,
      no further examination is necessary.
      Otherwise, a hash will be created for the blank node using
      the algorithm in <a href="#hash-nd-quads" class="sectionRef"></a>
      invoked via <a href="#canon-algorithm" class="sectionRef"></a>.</p>

    <section id="hash-1d-quads-overview" class="informative">
      <h3>Overview</h3>

      <p>To determine whether the first degree information of a node <var>n</var> is unique,
        a <a>hash</a> is assigned to its <a>mention set</a>,
        <var>Q<sub>n</sub></var>.
        The first degree hash of a blank node <var>n</var>,
        denoted <var>h<sub>f</sub>(n)</var>,
        is the hash that results from <a href="#hash-1d-quads" class="sectionRef"></a>
        when passing <var>n</var>.
        Nodes with unique first degree hashes have unique first degree information.</p>

      <p>For consistency, <a>blank node identifiers</a> used in <var>Q<sub>n</sub></var>
        are replaced with placeholders in an [[N-Quads]] serialization of that quad.
        Every blank node component is replaced with either `_:a` or `_:z`,
        depending on if that component is <var>n</var> or not.</p>

      <p>The resulting serialized quads are then <a>code point ordered</a>,
        concatenated, and hashed.
        This hash is the first degree hash of <var>n</var>, <var>h<sub>f</sub>(n)</var>.</p>
    </section>

    <section id="hash-1d-quads-exampkes" class="informative">
      <h3>Examples</h3>

      <aside id="ex-unique-hashes"
            class="example"
            title="Unique hashes">
        <p>This example illustrates hashing quads containing
          blank nodes where hashing the statements mentioning
          those blank nodes generates unique results.</p>

        <figure id="fig-unique-hashes" style="text-align:center">
          <!-- Source for this file is at https://docs.google.com/drawings/d/1LQ6fp4a35lrEOKRMD20gcncUkoitX0eW8QI_U2mQnAs/edit?usp=sharing -->
          <object data="unique-hashes.svg" style="width: 75%" type="image/svg+xml" aria-describedby="fig-unique-hashes-alt">
            <p id="fig-unique-hashes-alt">
              The image represents the graph described in
              <a href="#ex-unique-hashes-input">
                the following code block
              </a>.</p>
          </object>
          <figcaption>An illustration of a graph resulting in unique hashes.<br/>
            Image available in
            <a href="unique-hashes.svg" title="SVG image of a unique hashes">
              <abbr title="Scalable Vector Graphics">SVG</abbr>
            </a>.</figcaption>
        </figure>

        <pre id="ex-unique-hashes-input"
             data-transform="updateExample"
             title="Graph with blank nodes resulting in unique hashes">
          <!--
            :p :q _:b0 .
            :p :r _:b1 .
            _:b0 :s :u .
            _:b1 :t :u .
          -->
        </pre>

        <p>The algorithm will be called twice, with each blank node (`_:b0` and `_:b1`).
          Running the algorithm with the reference node `_:b0` results in the
          following quads, after replacing blank nodes:</p>

        <pre data-transform="updateExample">
          <!--
            :p :q _:a .
            _:a :s :u .
          -->
        </pre>

        <p>These are then serialized to N-Quads, concatenated and hashed
          using the <a>hash algorithm</a> (SHA-256) resulting in
          `21d1dd5ba21f3dee9d76c0c00c260fa6f5d5d65315099e553026f4828d0dc77a`.</p>

        <p>The algorithm is run a second time with the reference node `_:b1` resulting
          in the following quads:</p>

        <pre data-transform="updateExample">
          <!--
            :p :r _:a .
            _:a :t :u .
          -->
        </pre>

        <p>These are then serialized to N-Quads, concatenated and hashed as before resulting in
          `6fa0b9bdb376852b5743ff39ca4cbf7ea14d34966b2828478fbf222e7c764473`.</p>

        <p>Thus the generated hashes each reference just a single blank node,
          allowing the canonicalization algorithm to use only the
          Hash First Degree Quads algorithm.</p>
      </aside>

      <aside id="ex-shared-hashes"
            class="example"
            title="Shared hashes">
        <p>This example illustrates hashing quads containing
          blank nodes where hashing the statements mentioning
          those blank nodes have overlapping results.</p>

        <figure id="fig-shared-hashes" style="text-align:center">
          <!-- Source for this file is at https://docs.google.com/drawings/d/1HWpz8S-PNaWi02-utF62HAMd_0b-AF_tHNSRRUQILbU/edit?usp=sharing -->
          <object data="shared-hashes.svg" style="width: 75%" type="image/svg+xml" aria-describedby="fig-shared-hashes-alt">
            <p id="fig-shared-hashes-alt">
              The image represents the graph described in
              <a href="#ex-shared-hashes-input">
                the following code block
              </a>.</p>
          </object>
          <figcaption>An illustration of a graph resulting in shared hashes.<br/>
            Image available in
            <a href="shared-hashes.svg" title="SVG image of a graph resulting in shared hashes">
              <abbr title="Scalable Vector Graphics">SVG</abbr>
            </a>.</figcaption>
        </figure>
          
        <pre id="ex-shared-hashes-input"
             data-transform="updateExample"
             title="Graph with blank nodes resulting in shared hashes">
          <!--
            :p :q _:b0 .
            :p :q _:b1 .
            _:b0 :p _:b2 .
            _:b1 :p _:b3 .
            _:b2 :r _:b3 .
          -->
        </pre>

        <p>The algorithm will be called four times, with each blank node
          (`_:b0`, `_:b1`, `_:b2`, and `_:b3`).
          Running the algorithm with the reference node `_:b0` results in the
          following quads, after replacing blank nodes:</p>

        <pre data-transform="updateExample">
          <!--
            :p :q _:a .
            _:a :p _:z .
          -->
        </pre>

        <p>Which hashes to: `3b26142829b8887d011d779079a243bd61ab53c3990d550320a17b59ade6ba36`.</p>

        <p>Note that using reference node `_:b1` results in the same quads,
          and thus results in the same hash.</p>

        <p>Using the reference node `_:b2` results in the following quads:</p>

        <pre data-transform="updateExample">
          <!--
            _:z :p _:a .
            _:a :r _:z .
          -->
        </pre>

        <p>Which hashes to: `15973d39de079913dac841ac4fa8c4781c0febfba5e83e5c6e250869587f8659`.</p>

        <p>Lastly, using the reference node `_:b3` results in the following quads:</p>

        <pre data-transform="updateExample">
          <!--
            _:z :r _:a .
            _:z :p _:a .
          -->
        </pre>

        <p>Which hashes to: `3b26142829b8887d011d779079a243bd61ab53c3990d550320a17b59ade6ba36`.</p>

        <p>The hashes for `_:b2` and `_:b3` are unique, but `_:b0`,
          and `_:b1` share a common hash,
          which will require the use of the
          <a href="#hash-nd-quads-algorithm">Hash N-Degree Quads Algorithm</a>,
          as it is necessary to consider quads further removed from the direct mentions
          to determine a unique hash.</p>
      </aside>
    </section>

    <section id="hash-1d-quads-algorithm">
      <h3>Algorithm</h3>

      <p>This algorithm takes the <a>canonicalization state</a> and a
        <dfn>reference blank node identifier</dfn> as inputs.</p>

      <ol>
        <li id="h1d-1">Initialize <dfn>nquads</dfn> to an empty list. It will be
          used to store quads in [[N-Quads]] format.</li>
        <li id="h1d-2">Get the list of <a>quads</a> <var>quads</var>
          from the <a data-cite="INFRA#map-entry">map entry</a> for
          <a>reference blank node identifier</a> in the
          <a>blank node to quads map</a>.</li>
        <li id="h1d-3">For each <a>quad</a> <var>quad</var> in <var>quads</var>:
          <ol>
            <li id="h1d-3-1">Serialize the <a>quad</a> in [[N-Quads]] format with the
              following special rule:
              <ol>
                <li id="h1d-3-1-1">If any component in <var>quad</var> is an
                  <a>blank node</a>, then serialize it using a
                  special identifier as follows:
                  <ol>
                    <li id="h1d-3-1-1-1">If the <a>blank node</a>'s existing
                    <a>blank node identifier</a> matches the
                    <a>reference blank node identifier</a> then use the
                    <a>blank node identifier</a> <code>_:a</code>,
                    otherwise, use the <a>blank node identifier</a>
                    <code>_:z</code>.</li>
                  </ol>
                </li>
              </ol>
              <p class="issue" data-number="15">
                Note potential need to normalize literals to their
                canonical representation here as well,
                if not done on the original <a>input dataset</a>.</p>
            </li>
          </ol>
        </li>
        <li id="h1d-4">Sort <a>nquads</a> in <a>Unicode code point order</a>.</li>
        <li id="h1d-5">Return the <a>hash</a> that results from passing the sorted,
          joined <a>nquads</a> through the
          <a>hash algorithm</a>.</li>
      </ol>
    </section>
  </section>

  <section id="hash-related-blank-node" class="algorithm">
    <h2>Hash Related Blank Node</h2>

    <section id="hash-related-bn-overview" class="informative">
      <h3>Overview</h3>

      <p class="ednote">The text from the Arnold/Longley paper
        is a bit opaque here; recasting this in simpler terms
        would be more useful for the target audience.</p>
    </section>

    <section id="hash-related-algorithm">
      <h3>Algorithm</h3>

      <p>This algorithm creates a <a>hash</a> to identify how one
        <a>blank node</a> is related to another. It takes the
        <a>canonicalization state</a>, a <var>related</var>
        <a>blank node identifier</a>, a <var>quad</var>, an
        <a>identifier issuer</a>, <var>issuer</var>, and a
        <a>string</a> <var>position</var> as inputs.</p>

      <ol>
        <li id="hrbn-1">Set the <var>identifier</var> to use for <var>related</var>, preferring
          first the canonical identifier for <var>related</var> if issued, second
          the identifier issued by <var>issuer</var> if issued, and last, if
          necessary, the result of the
          <a href="#hash-1d-quads">Hash First Degree Quads algorithm</a>,
          passing <var>related</var>.
        </li>
        <li id="hrbn-2">Initialize a <a>string</a> <var>input</var> to the value of
          <var>position</var>.</li>
        <li id="hrbn-3">If <var>position</var> is not <code>g</code>, append
          <code>&lt;</code>, the value of the <a>predicate</a> in
          <var>quad</var>, and <code>&gt;</code> to <var>input</var>.</li>
        <li id="hrbn-4">Append <var>identifier</var> to <var>input</var>.</li>
        <li id="hrbn-5">Return the <a>hash</a> that results from passing <var>input</var>
          through the <a>hash algorithm</a>.</li>
      </ol>
    </section>
  </section>

  <section id="hash-nd-quads" class="algorithm">
    <h2>Hash N-Degree Quads</h2>

    <p>This algorithm calculates a <a>hash</a> for a given <a>blank node</a>
      across the <a>quads</a> in a <a>dataset</a> in which that blank node
      is a component for which the hash does not uniquely identify that blank node.
      This is done by expanding the search from quads directly referencing that
      blank node (the <a>mention set</a>), to those quads
      which contain nodes which are also components of quads in the mention set,
      called the <a>gossip path</a>.
      This process proceeds in every greater degrees of indirection until
      a unique hash is obtained.</p>

    <p class="ednote">There may also be better names for the two algorithms.</p>

    <p class="ednote">The 'path' terminology could also be changed to better
      indicate what a path is (a particular deterministic serialization for
      a subgraph/subdataset of nodes without globally-unique identifiers).</p>

    <section id="hash-nd-quads-overview" class="informative">
      <h3>Overview</h3>

      <p>Usually, when trying to determine if two nodes in a graph are
        equivalent, you simply compare their identifiers. However, what if the
        nodes don't have identifiers? Then you must determine if the two nodes
        have equivalent connections to equivalent nodes all throughout the
        whole graph. This is called the <a>graph isomorphism</a> problem. This
        algorithm approaches this problem by considering how one might draw
        a graph on paper. You can test to see if two nodes are equivalent
        by drawing the graph twice. The first time you draw the graph the
        first node is drawn in the center of the page. If you can draw the
        graph a second time such that it looks just like the first, except
        the second node is in the center of the page, then the nodes are
        equivalent. This algorithm essentially defines a deterministic way to
        draw a graph where, if you begin with a particular node, the graph
        will always be drawn the same way. If two graphs are drawn the same way
        with two different nodes, then the nodes are equivalent. A
        <a>hash</a> is used to indicate a particular way that the graph
        has been drawn and can be used to compare nodes.</p>

      <p>When two blank nodes have the same first degree hash,
        extra steps must be taken to detect global,
        or <em>N</em>-degree, distinctions.
        All information that is in any way connected to the blank node <var>n</var>
        through other blank nodes, even transitively, must be considered.</p>

      <p>To consider all transitive information,
        the algorithm traverses and encodes all possible paths of incident
        mentions emanating from <var>n</var>, called <a>gossip paths</a>,
        that reach every unlabeled blank node connected to <var>n</var>.
        Each unlabeled blank node is assigned a temporary label
        in the order in which it is reached in the
        gossip path being explored.
        The mentions that are traversed to reach
        connected blank nodes are encoded in these paths via related hashes.
        This provides a deterministic way to order all paths coming from <var>n</var> that
        reach all blank nodes connected to n without relying on input blank
        node labels.</p>
  
      <p>This algorithm works in concert with the main canonicalization algorithm
        to produce a unique, deterministic identifier for a particular blank
        node. This <a>hash</a> incorporates all of the information that
        is connected to the blank node as well as how it is connected. It does
        this by creating deterministic paths that emanate out from the blank
        node through any other adjacent blank nodes.</p>

      <p>Ultimately, the algorithm selects a shortest <a>gossip path</a>,
        distributing canonical labels to the unlabeled blank nodes
        in the order in which they appear in this path.
        The hash of this encoded shortest path,
        called the N-degree hash of <var>n</var>,
        distinguishes <var>n</var> from other blank nodes in the dataset.</p>

      <p>For clarity, we consider a <a>gossip path</a> encoded via the string <var>s</var>
        to be shortest provided that:</p>

      <ol>
        <li>The length of <var>s</var> is less than or equal to the length
          of any other gossip path string <var>sâ€²</var>.</li>
        <li>If <var>s</var> and <var>sâ€²</var> have the same length (as strings),
          then <var>s</var> is <a>code point ordered</a> less than or equal to <var>sâ€²</var>.</li>
      </ol>

      <p>For example, <em>abc</em> is shorter than <em>bbc</em>,
        whereas <em>abcd</em> is longer than <em>bcd</em>.</p>

      <p>The following provides a high level outline for how the N-degree hash of <var>n</var>
        is computed along the shortest <a>gossip path</a>.
        Note that the full algorithm considers all gossip paths,
        ultimately returning the <a>hash</a> of the shortest encoded path.</p>

      <ol>
        <li id="ndh-hl-s1"><strong>Compute related hashes</strong>.
          Compute the related hash <var>H<sub>n</sub></var> set for <var>n</var>,
          i.e., all first degree <a>mentions</a> between <var>n</var> and another blank node.
          Note that this includes both labeled and unlabeled blank nodes.</li>
        <li id="ndh-hl-s2"><strong>Explore mentions</strong>.
          Given the related hash <var>x</var> in <var>H<sub>n</sub></var>,
          record <var>x</var> in the data to hash <var>D<sub>n</sub></var>.
          Determine whether each blank node reachable via the <a>mention</a> with related hash <var>x</var>
          has already received a label.
          <ol>
            <li id="ndh-hl-s2-1"><strong>Record the labels of labeled nodes</strong>.
              If a blank node already has a label,
              record its label in <var>D<sub>n</sub></var> once for every
              <a>mention</a> with related hash <var>x</var>.
              Skip to the next related hash in <var>H<sub>n</sub></var>
              and repeat <a href="#ndh-hl-s2">step 2</a>.</li>
            <li id="ndh-hl-s2-2"><strong>Distribute and record temporary labels to unlabeled nodes</strong>.
              For each unlabeled blank node,
              assign it a temporary label according to the order in which it is reached in the gossip path,
              recording its given label in <var>D<sub>n</sub></var> (including repetitions).
              Add each unlabeled node to the recursion list <var>R<sub>n</sub>(x)</var>
              in this same order (omitting repetitions).</li>
            <li id="ndh-hl-s2-3"><strong>Recurse on newly labeled nodes</strong>.
              For each <var>n<sub>i</sub></var> in <var>R<sub>n</sub>(x)</var>
              <ol>
                <li id="ndh-hl-s2-3-1">Record its label in <var>D<sub>n</sub></var></li>
                <li id="ndh-hl-s2-3-2">Append &lt; <var>r(i)</var> > to <var>D<sub>n</sub></var>
                  where <var>r(i)</var> is the data to hash that results from returning to
                  <a href="#ndh-hl-s1">step 1</a>,
                  replacing <var>n</var> with <var>n<sub>i</sub></var>.</li>
              </ol>
            </li>
          </ol>
        </li>
        <li id="ndh-hl-s3"><strong>Compute the <em>N</em>-degree hash of n</strong>.
          Hash <var>D<sub>n</sub></var> to return the <em>N</em>-degree hash of <var>n</var>,
          namely <var>h<sub>N</sub>(n)</var>.
          Return the updated issuer <var>I<sub>n</sub></var>
          that has now distributed temporary labels to all unlabeled blank nodes connected to <var>n</var>.</li>
      </ol>

      <p>As described above in <a href="#ndh-hl-s2-3">step 2.3</a>,
        <var>HN</var> recurses on each unlabeled blank node
        when it is first reached along the <a>gossip path</a> being explored.
        This recursion can be visualized as moving along the path from <var>n</var>
        to the blank node <var>n<sub>i</sub></var> that is receiving a temporary identifier.
        If, when recursing on <var>n<sub>i</sub></var>,
        another unlabeled blank node <var>n<sub>j</sub></var> is discovered,
        the algorithm again recurses.
        Such a recursion traces out the <a>gossip path</a> from <var>n</var>
        to <var>n<sub>j</sub></var> via <var>n<sub>i</sub></var>.</p>

      <p>The recursive hash <var>r(i)</var> is the <a>hash</a> returned from
        the completed recursion on the node <var>n<sub>i</sub></var>
        when computing <var>h<sub>N</sub>(n)</var>.
        Just as <var>h<sub>N</sub>(n)</var> is the hash of <var>D<sub>n</sub></var>,
        we denote the data to hash in the recursion on <var>n<sub>i</sub></var>
        as <var>D<sub>i</sub></var>.
        So, <var>r(i)</var> = <var>h(D<sub>i</sub>)</var>.
        For each related hash <var>x</var> âˆˆ <var>H<sub>n</sub></var>,
        <var>R<sub>n</sub>(x)</var> is called the <em>recursion list</em> on
        which the algorithm recurses.</p>
    </section>

    <section id="hash-nd-quads-exampkes" class="informative">
      <h3>Examples</h3>

      <p class="ednote">
        Add some examples ranging from simple to complicated and resource consuming.
      </p>
    </section>

    <section id="hash-nd-quads-algorithm">
      <h3>Algorithm</h3>

      <div class="issue" data-number="16">
        An additional input to this algorithm should be added that
        allows it to be optionally skipped and throw an error if any
        equivalent related hashes were produced that must be permuted
        during step 5.4.4. For practical uses of the algorithm, this step
        should never be encountered and could be turned off, disabling
        canonizing datasets that include a need to run it as a security
        measure.
      </div>

      <p>The inputs to this algorithm are the <a>canonicalization state</a>,
        the <var>identifier</var> for the <a>blank node</a> to
        recursively hash quads for, and path identifier <var>issuer</var> which is
        an <a>identifier issuer</a> that issues temporary
        <a>blank node identifier</a>s. The output from this algorithm
        will be a <a>hash</a> and the <a>identifier issuer</a> used
        to help generate it.</p>

      <ol>
        <li id="hndq-1">Create a <var>hash to related blank nodes map</var> for storing
          hashes that identify related <a>blank nodes</a>.</li>
        <li id="hndq-2">Get a reference, <var>quads</var>, to the list of <a>quads</a>
          from the <a data-cite="INFRA#map-entry">map entry</a>
          for <var>identifier</var>
          in the <a>blank node to quads map</a>.</li>
        <li id="hndq-3">For each <var>quad</var> in <var>quads</var>:
          <ol>
            <li id="hndq-3-1">For each <var>component</var> in <var>quad</var>, where <var>component</var>
              is the <a>subject</a>, <a>object</a>, or
              <a>graph name</a>, and it is a
              <a>blank node</a> that is not identified by
              <var>identifier</var>:
              <ol>
                <li id="hndq-3-1-1">Set <var>hash</var> to the result of the
                  <a href="#hash-related-blank-node">Hash Related Blank Node algorithm</a>,
                  passing the <a>blank node identifier</a> for
                  <var>component</var> as <var>related</var>, <var>quad</var>,
                  <var>path identifier issuer</var> as <var>issuer</var>, and
                  <var>position</var> as either <code>s</code>, <code>o</code>, or
                  <code>g</code> based on whether <var>component</var> is a
                  <a>subject</a>, <a>object</a>,
                  <a>graph name</a>, respectively.</li>
                <li id="hndq-3-1-2">Add a mapping of <var>hash</var> to the
                  <a>blank node identifier</a> for <var>component</var>
                  to <var>hash to related blank nodes map</var>, adding an entry
                  as necessary.</li>
              </ol>
            </li>
          </ol>
        </li>
        <li id="hndq-4">Create an empty string, <var>data to hash</var>.</li>
        <li id="hndq-5">For each <var>related hash</var> to <var>blank node list</var> mapping in
          <var>hash to related blank nodes map</var>, <a>code point ordered</a>
          by <var>related hash</var>:
          <ol>
            <li id="hndq-5-1">Append the <var>related hash</var> to the <var>data to hash</var>.</li>
            <li id="hndq-5-2">Create a <a>string</a> <var>chosen path</var>.</li>
            <li id="hndq-5-3">Create an unset <var>chosen issuer</var> variable.</li>
            <li id="hndq-5-4">For each <var>permutation</var> of <var>blank node list</var>:
              <ol>
                <li id="hndq-5-4-1">Create a copy of <var>issuer</var>, <var>issuer copy</var>.</li>
                <li id="hndq-5-4-2">Create a <a>string</a> <var>path</var>.</li>
                <li id="hndq-5-4-3">Create a <var>recursion list</var>, to store
                  <a>blank node identifiers</a> that must be
                  recursively processed by this algorithm.</li>
                <li id="hndq-5-4-4">For each <var>related</var> in <var>permutation</var>:
                  <ol>
                    <li id="hndq-5-4-4-1">If a canonical identifier has been issued for
                      <var>related</var>, append it to <var>path</var>.</li>
                    <li id="hndq-5-4-4-2">Otherwise:
                      <ol>
                        <li id="hndq-5-4-4-2-1">If <i>issuer copy</i> has not issued
                          an identifier for <var>related</var>, append
                          <var>related</var> to <var>recursion list</var>.</li>
                        <li id="hndq-5-4-4-2-2">Use the
                          <a href="#issue-identifier">Issue Identifier algorithm</a>,
                          passing <var>issuer copy</var> and <var>related</var> and
                          append the result to <var>path</var>.</li>
                      </ol>
                    </li>
                    <li id="hndq-5-4-4-3">If <var>chosen path</var> is not empty and the length
                      of <var>path</var> is greater than or equal to the length
                      of <var>chosen path</var> and <var>path</var> is
                      greater than <var>chosen path</var> when
                      considering <a>code point order</a>,
                      then skip to the next <var>permutation</var>.
                    </li>
                  </ol>
                </li>
                <li id="hndq-5-4-5">For each <var>related</var> in <var>recursion list</var>:
                  <ol>
                    <li id="hndq-5-4-5-1">Set <var>result</var> to the result of recursively executing
                      the
                      <a href="#hash-nd-quads">Hash N-Degree Quads algorithm</a>,
                      passing <var>related</var> for <var>identifier</var> and
                      <var>issuer copy</var> for <var>path identifier issuer</var>.</li>
                    <li id="hndq-5-4-5-2">Use the
                      <a href="#issue-identifier">Issue Identifier algorithm</a>,
                      passing <var>issuer copy</var> and <var>related</var> and
                      append the result to <var>path</var>.</li>
                    <li id="hndq-5-4-5-3">Append <code>&lt;</code>, the <a>hash</a> in
                      <var>result</var>, and <code>&gt;</code> to <var>path</var>.</li>
                    <li id="hndq-5-4-5-4">Set <var>issuer copy</var> to the
                      <a>identifier issuer</a> in result.</li>
                    <li id="hndq-5-4-5-5">If <var>chosen path</var> is not empty and the length
                      of <var>path</var> is greater than or equal to the length
                      of <var>chosen path</var> and <var>path</var> is
                      greater than <var>chosen path</var> when considering <a>code point order</a>,
                      then skip to the next <var>permutation</var>.</li>
                  </ol>
                </li>
                <li id="hndq-5-4-6">If <var>chosen path</var> is empty or <var>path</var> is
                  less than <var>chosen path</var> when considering <a>code point order</a>,
                  set <var>chosen path</var> to <var>path</var> and <var>chosen issuer</var>
                  to <var>issuer copy</var>.</li>
              </ol>
            </li>
            <li id="hndq-5-5">Append <var>chosen path</var> to <var>data to hash</var>.</li>
            <li id="hndq-5-6">Replace <var>issuer</var>, by reference, with
              <var>chosen issuer</var>.</li>
          </ol>
        </li>
        <li id="hndq-6">Return <var>issuer</var> and the <a>hash</a> that results from
          passing <var>data to hash</var> through the
          <a>hash algorithm</a>.</li>
      </ol>
    </section>
  </section>
</section>

<section id="privacy-considerations">
  <h2>Privacy Considerations</h2>

  <p class="ednote">TBD</p>
</section>

<section id="security-considerations">
  <h2>Security Considerations</h2>

  <p class="ednote">TBD</p>
</section>

<section id="use-cases" class="informative">
  <h2>Use Cases</h2>
  <p class="ednote">TBD</p>
</section>

<section id="examples" class="informative">
  <h2>Examples</h2>
  <p class="ednote">TBD</p>
</section>

<section id="urgna2021" class="appendix informative algorithm">
  <h2>URGNA2012</h2>
  <p>A previous version of this algorithm has light deployment. For purposes of identification,
    the algorithm is called the
    "Universal RDF Graph Canonicalization Algorithm 2012"
    (<abbr title="Universal RDF Graph Canonicalization Algorithm 2012"><dfn class="export">URGNA2012</dfn></abbr>),
    and differs from the stated algorithm in the following ways:</p>
  <ul>
    <li>In <a href="#hash-1d-quads" class="sectionRef"></a>, if any blank node was used in the <a>graph name</a>
      position in the <a>quad</a>, then the value was serialized using
      the special <a>blank node identifier</a>, <code>_:g</code>, instead of <code>_:z</code>.</li>
    <li>In <a href="#hash-related-blank-node" class="sectionRef"></a>, value of the <a>predicate</a>
      was not delimited by <code>&lt;</code> and <code>&gt;</code>; there
      were no delimiters.</li>
    <li>In <a href="#hash-nd-quads" class="sectionRef"></a>, the <var>position</var> parameter passed to
      the <a href="#hash-related-blank-node">Hash Related Blank Node algorithm</a>
      was instead modeled as a <var>direction</var> parameter, where it could have
      the value <code>p</code>, for property, when the related blank node was a
      <a>subject</a> and the value <code>r</code>, for reverse or reference, when
      the related blank node was an <a>object</a>. Since <a>URGNA2012</a> only normalized
      graphs, not datasets, there was no use of the <a>graph name</a> position.</li>
    <li>In <a href="#hash-nd-quads" class="sectionRef"></a>, building the
      <var>hash to related blank nodes map</var> was done as follows:
      <ol>
        <li id="urgna-1">For each <var>quad</var> in <var>quads</var>:
          <ol>
            <li id="urgna-1-1">If the <var>quad</var>'s <a>subject</a> is a <a>blank node</a> that does not
              match <var>identifier</var>, set <var>hash</var> to the result of the
                <a href="#hash-related-blank-node">Hash Related Blank Node algorithm</a>,
                passing the <a>blank node identifier</a> for
                <a>subject</a> as <var>related</var>, <var>quad</var>,
                <var>path identifier issuer</var> as <var>issuer</var>, and
                <code>p</code> as <var>position</var>.
            </li>
            <li id="urgna-1-2">Otherwise, if <var>quad</var>'s <a>object</a> is a <a>blank node</a> that does
              not match <var>identifier</var>, set <var>hash</var> to the result of the
                <a href="#hash-related-blank-node">Hash Related Blank Node algorithm</a>,
                passing the <a>blank node identifier</a> for
                <a>object</a> as <var>related</var>, <var>quad</var>,
                <var>path identifier issuer</var> as <var>issuer</var>, and
                <code>r</code> as <var>position</var>.
            </li>
            <li id="urgna-1-3">Otherwise, continue to the next quad.</li>
            <li id="urgna-1-4">Add a mapping of <var>hash</var> to the
              <a>blank node identifier</a> for the component
              that matched (<a>subject</a> or <a>object</a>) to
              <var>hash to related blank nodes map</var>, adding an entry
              as necessary.</li>
          </ol>
        </li>
      </ol>
    </li>
  </ul>
</section>

<section class="appendix informative" id="changes-from-fpwd">
  <h2>Changes since the First Public Working Draft of 24 November 2022</h2>
  <ul>
    <li class="issue" data-number="23">
      <a href="#hash-1d-quads" class="sectionRef"></a>
      was simplified to remove the `simple` flag,
      which was unused in existing implementations.
      The design of the algorithm was to use the
      assigned canonical <a>blank node identifier</a>,
      if available, instead of `_:a` or `_:z`,
      similar to how it is used in
      the related hash algorithm, but this text never made it into the spec
      before implementations moved forward.
      Therefore, the hashes here
      never change, making the loop based on the `simple`
      flag that calls this algorithm unnecessary; it needs to only run
      once.
    </li>
  </ul>
</section>
<section id="issue-summary" class="appendix informative"></section>

<section id="ack" class="appendix informative">
  <h2>Acknowledgements</h2>

  <p>The editors would like to thank Jeremy Carroll for his work on the
    graph canonicalization problem, Gavin Carothers for providing valuable
    feedback and testing input for the algorithm defined in this
    specification, Sir Tim Berners Lee for his thoughts on graph canonicalization
    over the years, JesÃºs Arias Fisteus for his work on a similar
    algorithm.</p>

  <p class="ednote">Acknowledge CCG and RCH WG. Consider using `.publ_ack.json`.</p>
        <div class="issue" data-number="19"></div>
</section>

</body>
</html>
